\documentclass[master]{subfiles}
\begin{document}
\section{Conclusion}
The paper aimed to answer how is the performance of machine learning agent affected by different feature vectors in the game of schnapsen. One of the most critical steps in the direction of forming the conclusion were the results from the botsâ€™ plays against each other and results. During the competition between these bots, the connection was drawn between the results and the phase in which they were playing. So, in phase 1 and 2, the ml\_extended version of the bot that is built on top of the default performed better than the default agent. The ml\_limited, the bot with a shorter feature vector, had considerably worse performance in comparison to the default bot. Ml\_mix bot has the worst performance. When it comes to only phase 2, the moment when both players reveal their cards, all bots performed worse in comparison to the default bot. The ratio of performance gain/loss stays consistent between testing in phase 1 and 2 and testing in phase 1. When it comes to the comparison of variations of ml bots to rand, rdeep, minimax and alpha-beta, ml\_extended has better performance on average. There is some connection found between the number of features implemented and win/loss ratio. However, the final conclusion related to that fact cannot be drawn at that moment due to the limited time. In order to prove that the larger feature vector, the better performance is, we would need to make more detailed research with a bigger amount of tournaments, feature vectors involved. However, the conclusion can be drawn that depending on the feature vector size and the phase being played, the performance of the bot will be different.
\end{document}